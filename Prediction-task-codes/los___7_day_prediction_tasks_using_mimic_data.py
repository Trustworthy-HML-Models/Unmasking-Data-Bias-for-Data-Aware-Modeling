# -*- coding: utf-8 -*-
"""LOS > 7 day  prediction tasks using MIMIC data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KJIZhFJkRt4mb_L0d4bMcYYTrQAnFXLL
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df_new = pd.read_csv('/content/sample_data/cohort_icu_length_of_stay_7__I50.csv')

stat = df_new['Age'].describe()
print(stat)

!pip install brewer2mpl

df_new.value_counts('gender')

import seaborn as sns
import matplotlib.pyplot as plt

sns.set_style('whitegrid')
plt.figure(figsize=(5, 3))
ax = sns.countplot(x='gender', data=df_new, palette='Set2', width=0.4)
plt.xlabel('Gender', fontsize=10,fontweight='bold')
plt.ylabel('Count', fontsize=10,fontweight='bold')
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)
plt.tight_layout()

# Calculate the percentage of M and F in the dataset
total_count = len(df_new)
m_count = len(df_new[df_new['gender'] == 'M'])
f_count = total_count - m_count
m_percent = round((m_count/total_count)*100, 1)
f_percent = round((f_count/total_count)*100, 1)

# Add text labels on top of the bars
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x()+p.get_width()/2,
            height+2,
            '{:.1f}%'.format(height/total_count*100),
            ha="center", fontsize=10,fontweight='bold')


plt.savefig('/content/sample_data/Gender.pdf', bbox_inches='tight', format='pdf')
plt.show()

df_new.value_counts('ethnicity').sort_index().index.str.lower()

# Define the mapping dictionary
racial_groupings = {
    'White': ['white', 'white - brazilian','white - eastern european', 'white - other european','white - russian','portuguese'],
    'Black': ['black/african', 'black/african american', 'black/cape verdean','black/caribbean island','south american'],
    'Hispanic/Latino': ['hispanic or latino','hispanic/latino - central american', 'hispanic/latino - columbian','hispanic/latino - cuban', 'hispanic/latino - dominican','hispanic/latino - guatemalan', 'hispanic/latino - honduran','hispanic/latino - mexican', 'hispanic/latino - puerto rican','hispanic/latino - salvadoran'],
    'Asian': ['asian', 'asian - asian indian','asian - chinese', 'asian - korean', 'asian - south east asian'],
    'Other': ['native hawaiian or other pacific islander','other','patient declined to answer', 'unable to obtain', 'unknown','american indian/alaska native','multiple race/ethnicity']
}

# Replace the original race values with the new groupings

df_new['ethnicity'] = df_new['ethnicity'].str.strip().str.lower()


def get_race_sub_group(race):
    for group, races in racial_groupings.items():
        if race in races:
            return group
    return 'Unknown'

df_new['race_sub_group'] = df_new['ethnicity'].apply(get_race_sub_group)

df_new.value_counts('race_sub_group')

all_subgroups = set(subgroup for sublist in racial_groupings.values() for subgroup in sublist)
# Get all possible race subgroups
all_subgroups = set(subgroup for sublist in racial_groupings.values() for subgroup in sublist)

# Get the unique values in the 'race' column of your dataframe
unique_races = set(df_new['ethnicity'].str.lower().unique())

# Find the subgroups that are not in the racial_groupings dictionary
missing_subgroups = unique_races.difference(all_subgroups)
print(f"Missing subgroups: {missing_subgroups}")

# Group by race_sub_group and count the number of occurrences
counts_by_race = df_new.groupby('race_sub_group').size()

# Define colors using brewer palette 'Set3'
colors = sns.color_palette('Set3', len(counts_by_race))

# Determine index of slice with largest percentage and move it out
explode = [0.1 if i == counts_by_race.argmax() else 0 for i in range(len(counts_by_race))]

# Generate a pie chart using the counts, colors, and explode values
fig, ax = plt.subplots()
ax.pie(counts_by_race, labels=counts_by_race.index, autopct='%1.1f%%',
       colors=colors, explode=explode, textprops={'fontsize': 10})
ax.axis('equal') 
ax.set_title('Distribution of LOS by race', y=1.1, fontsize=12)
plt.savefig('/content/sample_data/distribution of LOS by race pie.pdf', bbox_inches='tight', format='pdf')
plt.show()

# Get the count of each insurance type
insurance_counts = df_new['insurance'].value_counts()

# Set the color palette
colors = sns.color_palette('Paired', n_colors=len(insurance_counts))

# Create the count plot
sns.countplot(x='insurance', data=df_new, palette=colors)

# Print the value counts for each insurance type
print(df_new['insurance'].value_counts())

# Add labels to the plot
plt.xlabel('Insurance Type', fontsize=10, fontweight='bold')
plt.ylabel('Count', fontsize=10, fontweight='bold')
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)
plt.legend(fontsize=10)

# Set the figure size and layout
sns.set(rc={'figure.figsize': (6, 4)})
sns.set_style('whitegrid')
plt.tight_layout()

# Save the plot
plt.savefig('/content/sample_data/insurance_distribution_of_LOS_patients.pdf', bbox_inches='tight', format='pdf')

# Show the plot
plt.show()

from brewer2mpl import get_map
import math
race_sub_group_insurance = df_new.groupby(['race_sub_group', 'insurance']).size()

# Set the color map to 'Set2' with 4 colors
cmap = get_map('set3', 'qualitative', 8).mpl_colors

# Reshape the data to wide format, with insurance types as columns and race as index
race_sub_group_insurance = race_sub_group_insurance.unstack()

# Calculate the number of rows and columns of subplots based on the number of races
n_races = len(race_sub_group_insurance.index)
n_cols = int(math.ceil(math.sqrt(n_races)))
n_rows = int(math.ceil(n_races / n_cols))

# Create subplots
fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(10, 6))

# Flatten the axes array so that we can iterate over it using a single index
ax = ax.flatten()

for i, race in enumerate(race_sub_group_insurance.index):
    ax[i].set_title('Insurance Types for {}'.format(race), fontsize=12)
    pie_wedge_collection = ax[i].pie(race_sub_group_insurance.loc[race], colors=cmap, autopct='%1.1f%%', startangle=90, explode=(race_sub_group_insurance.loc[race] == race_sub_group_insurance.loc[race].min()) * 0.1)
    ax[i].set_ylabel('')

# Create a separate axis for the legend
legend_ax = fig.add_axes([1.05, 0.1, 0.05, 0.8])
legend_ax.axis('off')

# Create a legend for the pie charts
legend_ax.legend(pie_wedge_collection[0], race_sub_group_insurance.columns, loc='center',title='Insurance', fontsize=10)

# Hide any extra subplots
for i in range(n_races, n_rows * n_cols):
    ax[i].axis('off')

#plt.suptitle('Insurance Types by Race', fontsize=14)
plt.tight_layout()
plt.savefig('/content/sample_data/Insurance_by race of LOS patients pie.pdf', bbox_inches='tight', format='pdf')
plt.show()

gender_insurance_counts_label = df_new.groupby(['gender', 'insurance','label']).size()

# Reshape the data to wide format, with insurance types as columns and gender as index
gender_insurance_counts_label = gender_insurance_counts_label.unstack()
print(gender_insurance_counts_label)

race_insurance_counts_label = df_new.groupby(['race_sub_group', 'insurance','label']).size()

# Reshape the data to wide format, with insurance types as columns and gender as index
race_insurance_counts_label = race_insurance_counts_label.unstack()
print(race_insurance_counts_label)

# Calculate the percentages
total_counts = race_insurance_counts_label.sum(axis=1)
race_insurance_percentages_label = race_insurance_counts_label.div(total_counts, axis=0) * 100

# Round the percentages to three digits
race_insurance_percentages_label = race_insurance_percentages_label.round(3)

print(race_insurance_percentages_label)

race_insurance_counts_label_df = pd.read_csv('/content/sample_data/LOS gt 7 days heart disease analysis table.csv')
race_insurance_counts_label_df.head(5)

pip install -U kaleido

import plotly.express as px
import pandas as pd
import kaleido
import plotly.io as pio

# Create a sample dataset
data = pd.read_csv('/content/sample_data/LOS gt 7 days heart disease analysis table.csv')

# Create a stacked bar chart
fig = px.bar(data, x='race_sub_group', y='count', color='label', barmode='stack', facet_col='insurance', labels={'race_sub_group': '', 'count': 'Count'})
fig.for_each_annotation(lambda a: a.update(text=a.text.split("=")[-1]))

fig.update_layout({
    'xaxis': {'title': 'Ethnicity'},
    'font': {'size': 12},
    'legend': {'title': 'Label (0 - Not Readmitted; 1 - Readmitted)', 'font': {'size': 10}}
})
fig.write_image('/content/sample_data/Readmitted VS No based on Insurance and race final.pdf', format='pdf', engine='kaleido')



# Show the plot
fig.show()

# Create a stacked area chart
fig = px.area(data, x='insurance', y='count', color='label', line_group='race_sub_group', facet_col='race_sub_group', 
              labels={'insurance': '', 'count': 'Count'})

# Update the facet column labels to remove the '=' sign
fig.for_each_annotation(lambda a: a.update(text=a.text.split("=")[-1]))
# Update the x-axis tick labels for each subplot
fig.update_xaxes(categoryorder='array', categoryarray=['Medicaid', 'Medicare', 'Other'], 
                 tickangle=-80, tickfont_size=12) #facet_row='race_sub_group')
# Update the layout with axis titles and facet labels
fig.update_layout({
    'yaxis': {'title': 'Count'},
    'xaxis': {'title': 'Insurance', 'title_standoff': 20},
    'margin': {'t': 100, 'b': 100, 'l': 100, 'r': 100},
    'font': {'size': 12},
    'legend': {'title': 'Label (0 - LOS < 7 days; 1 - LOS > 7 days)', 'font': {'size': 10}}
})

fig.write_image('/content/sample_data/LOS < or > 7days based on Insurance and race area stacked bar chart.pdf', format='pdf', engine='kaleido')

# Show the plot
fig.show()

import plotly.express as px
import pandas as pd


# Group the data by 'race_sub_group', 'insurance', and 'label' and calculate the counts
grouped_data = data.groupby(['race_sub_group', 'insurance', 'label']).sum('count').reset_index()

# Calculate the total count for each race subgroup and insurance
grouped_data['total_count'] = grouped_data.groupby(['race_sub_group', 'insurance'])['count'].transform('sum')

# Calculate the percentage of dead and alive for each insurance subgroup within each race subgroup
grouped_data['percentage_readmitted'] = grouped_data.apply(lambda row: row['count'] / row['total_count'] if row['label'] == 1 else 0, axis=1) * 100
grouped_data['percentage_not_readmitted'] = grouped_data.apply(lambda row: row['count'] / row['total_count'] if row['label'] == 0 else 0, axis=1) * 100

# Define custom colors for the bars
colors = ['#1f77b4', '#ff7f0e']

# Create a stacked bar chart
fig = px.bar(grouped_data, x='race_sub_group', y=['percentage_readmitted', 'percentage_not_readmitted'],
             color_discrete_sequence=colors, facet_col='insurance',
             labels={'race_sub_group': '', 'value': 'Percentage'})

fig.for_each_annotation(lambda a: a.update(text=a.text.split("=")[-1]))

# Update the bar labels
fig.update_traces(texttemplate='%{y:.2f}%', textposition='inside', textfont={'size': 8})

fig.update_layout({
    'xaxis': {'title': 'Ethnicity'},
    'yaxis': {'title': 'Percentage'},
    'legend': {'title': 'Label (0 - LOS < 7 days; 1 - LOS > 7 days)', 'font': {'size': 10}},
    'font': {'size': 8}
})

fig.write_image('/content/sample_data/LOS < or > 7 days based on Insurance and race percentage bar chart.pdf', format='pdf', engine='kaleido')
# Show the plot
fig.show()

import plotly.express as px
import pandas as pd


# Group the data by 'race_sub_group', 'insurance', and 'label' and calculate the counts
grouped_data = data.groupby(['race_sub_group', 'insurance', 'label']).sum('count').reset_index()

# Calculate the total count for each race subgroup and insurance
grouped_data['total_count'] = grouped_data.groupby(['race_sub_group', 'insurance'])['count'].transform('sum')

# Calculate the percentage of dead and alive for each insurance subgroup within each race subgroup
grouped_data['percentage_dead'] = grouped_data.apply(lambda row: row['count'] / row['total_count'] if row['label'] == 1 else 0, axis=1) * 100
grouped_data['percentage_alive'] = grouped_data.apply(lambda row: row['count'] / row['total_count'] if row['label'] == 0 else 0, axis=1) * 100

# Define custom light colors for dead and alive
colors = {'percentage_dead': '#AEC7E8', 'percentage_alive': '#FFBB78'}

# Create a grouped horizontal bar chart
fig = px.bar(grouped_data, x=['percentage_dead', 'percentage_alive'], y='race_sub_group',
             color='insurance', barmode='group',
             color_discrete_map=colors,
             facet_col='label',
             labels={'race_sub_group': 'Ethnicity', 'value': 'Percentage', 'label': 'Label'},
             title='')

# Update the bar labels and font size
fig.update_traces(texttemplate='%{x:.2f}%', textposition='inside', textfont={'size': 18})

fig.update_layout({
    'xaxis': {'title': 'Percentage'},
    'yaxis': {'title': 'Ethnicity'},
    'legend': {'title': 'Insurance', 'font': {'size': 10}},
    'font': {'size': 12}
})

fig.update_xaxes(title_text='Percentage Alive', col=1)
fig.update_xaxes(title_text='Percentage Dead', col=2)

fig.write_image('/content/sample_data/LOS < or > 7 days based on Insurance and race percentage grouped horizontal bar chart.pdf', format='pdf', engine='kaleido')

# Show the plot
fig.show()

"""Similar to above prediction tasks, we first retrieved  the cohort based on the research question and here its the ICU patients with heart failure inorder to predict the length of stay > 7 days, as its the most widely predicted task in that category as per the above survey. Below insights are obtained from the analysis of the dataset,

The median age of patients in this cohort was 72, with 55\% being male and 45\% being female. The dataset primarily consisted of the White demographic, accounting for 69\% of the cohort, followed by Black, Other, Hispanic/Latino, and Asian subgroups, which aligns with the geographical context of data collection. Consequently, the findings of our analysis are significantly influenced by the White subgroup across various categories.

In terms of insurance coverage, the majority of patients across all ethnicities within the cohort opted for Medicare insurance (60\%), followed by Other (35\%), while Medicaid had the lowest utilization rate (5\%). Notably, both Other and Black patients exhibited the highest usage of Medicare insurance apart from White, followed by hispanic/latino and Asian patients. Asian pateints were the only one to prefer other insurance in comparision to medicare which was most utilized by all the other sub-groups. This observations suggest that Asian subgroups may have the presence of private insurance or a higher socio-economic status or a relatively younger patient population within their community. It is important to note that the MIMIC data does not provide detailed information about the specifics of other insurance coverage, making it challenging to draw definitive conclusions about their preferences.

Conversely, Medicaid exhibited lowest (4.3%) patient counts across all racial subgroups. Interestingly, despite the Caucasian subgroup being the most populous, only 2.6% of them utilized Medicaid insurance, which is relatively lower compared to rest of the subgroups highlighting socio-economic disparities among the racial subgroups. From the data analysis we could see that Asian and other subgroup people have a ICU lenght of stay > 7 days irrespective of their insurance suggesting a disparity in the quality of healthcare treatment for minority group patients. Inorder to investigate further we conducted chi-square (p value = 1.30e^-07) and ANOVA (0.05) statistical tests and found that there is an association between the length of stay in the ICU for heart failure and the variables of ethnicity and insurance.  



#Discussion

The above analysis of the ICU LOS of heart failure patients >7 days data reveals potential disparities in treatment based on ethnicity and insurance coverage emphasizing the presence of inherent biases within healthcare systems. From the results of the analysis, it is imperative to address the performance of the models across different ethnic demographics for building a fair, generalized and data-aware HML models. 
"""

import pandas as pd
from scipy.stats import chi2_contingency

# Create the dataframe
data = {
    'race_sub_group': ['Asian', 'Asian', 'Asian', 'Asian', 'Asian', 'Asian', 'Black', 'Black', 'Black', 'Black', 'Black', 'Black', 
                       'Hispanic/Latino', 'Hispanic/Latino', 'Hispanic/Latino', 'Hispanic/Latino', 'Hispanic/Latino', 'Hispanic/Latino', 
                       'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'White', 'White', 'White', 'White', 'White','White'],
    'insurance': ['Medicaid', 'Medicaid', 'Medicare', 'Medicare', 'Other', 'Other', 'Medicaid', 'Medicaid', 'Medicare', 'Medicare', 'Other', 'Other', 
                  'Medicaid', 'Medicaid', 'Medicare', 'Medicare', 'Other', 'Other', 'Medicaid', 'Medicaid', 'Medicare', 'Medicare', 'Other', 'Other', 
                  'Medicaid', 'Medicaid', 'Medicare', 'Medicare', 'Other','Other'],
    'label': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1],
    'count': [41, 13, 163, 23, 184, 39, 201, 25, 1209, 159, 899, 132, 84, 8, 253, 44, 239, 38, 120, 32, 1042, 218, 810, 170, 297, 57, 7838, 1136, 3860, 635]
}

df = pd.DataFrame(data)

# Create a contingency table
contingency_table = pd.pivot_table(df, values='count', index=['race_sub_group', 'insurance'], columns='label', fill_value=0)

# Perform the chi-square test
chi2, p, _, _ = chi2_contingency(contingency_table)

# Print the contingency table
print("Contingency Table:")
print(contingency_table)

# Print the test statistic and p-value
print("Chi-square test statistic:", chi2)
print("p-value:", p)

# Perform ANOVA
from scipy import stats
result = stats.f_oneway(
    df[df['race_sub_group'] == 'Asian']['count'],
    df[df['race_sub_group'] == 'Black']['count'],
    df[df['race_sub_group'] == 'Hispanic/Latino']['count'],
    df[df['race_sub_group'] == 'Other']['count'],
    df[df['race_sub_group'] == 'White']['count']
)

# Print the ANOVA test result
print("ANOVA test result:")
print("F-value:", result.statistic)
print("p-value:", result.pvalue)